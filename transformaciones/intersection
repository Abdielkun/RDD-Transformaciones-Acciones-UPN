from pyspark import SparkContext

sc = SparkContext("local", "Intersection Example")

# Crear dos RDDs de ejemplo
rdd1 = sc.parallelize([1, 2, 3, 4, 5])
rdd2 = sc.parallelize([3, 4, 5, 6, 7])

# Realizar la intersección de ambos RDDs
rdd_intersection = rdd1.intersection(rdd2)

# Mostrar los elementos de la intersección
print("Elementos en la intersección:", rdd_intersection.collect())

sc.stop()
